"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–æ—Å–Ω–æ–≤–Ω–æ–π –¥–∏–∞–ª–æ–≥)."""

from __future__ import annotations

import asyncio
from datetime import datetime

from aiogram import F, Router
from aiogram.types import Message
from beartype import beartype

from src.ai.ollama_client import OllamaClient
from src.ai.prompts import create_sales_chat_messages
from src.bot.keyboards import contextual_quick_replies
from src.database.context import ConversationContext
from src.knowledge.faq_loader import KnowledgeBase
from src.knowledge.search import format_faq_results, quick_faq_check, search_faq
from src.utils.intent_detection import detect_user_intent, should_show_hints
from src.utils.lead_scoring import calculate_lead_score, detect_funnel_stage
from src.utils.loading_indicator import LoadingIndicator
from src.utils.onboarding import get_onboarding_tip, should_show_onboarding_tip
from src.utils.text_filter import clean_text

router = Router()

# –ö—ç—à –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–¥—Å–∫–∞–∑–∫–∏
_last_tips_shown: dict[int, int] = {}


@router.message(F.text)
@beartype
async def handle_text_message(
    message: Message,
    knowledge_base: KnowledgeBase,
    context: ConversationContext,
    ollama_client: OllamaClient,
) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        knowledge_base: –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        context: –ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–æ–≤
        ollama_client: –ö–ª–∏–µ–Ω—Ç Ollama –¥–ª—è AI –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    """
    if not message.from_user or not message.text:
        return

    user_id = message.from_user.id
    user_question = message.text

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    intent = detect_user_intent(user_question)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î
    await context.save_message(
        user_id=user_id,
        role="user",
        content=user_question,
    )

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    conversation_history = await context.get_context(user_id, limit=5)

    # –û—Ü–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ª–∏–¥–∞ –∏ —ç—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏
    lead_score = calculate_lead_score(
        user_message=user_question,
        conversation_history=conversation_history,
        intent=intent,
    )

    funnel_stage = detect_funnel_stage(
        conversation_history=conversation_history,
        lead_score=lead_score,
    )

    # –ü–æ–ø—ã—Ç–∫–∞ 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ FAQ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–±–µ–∑ AI)
    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –û–ß–ï–ù–¨ —Ö–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (score >= 0.75) - –æ—Ç–≤–µ—Ç–∏—Ç—å –º–≥–Ω–æ–≤–µ–Ω–Ω–æ
    # –ü–æ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–±–∏–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥
    quick_result = quick_faq_check(user_question, knowledge_base, min_score=0.75)
    
    ai_response = None
    if quick_result:
        # –ù–∞–π–¥–µ–Ω —Ç–æ—á–Ω—ã–π FAQ –æ—Ç–≤–µ—Ç - –æ—Ç–≤–µ—á–∞–µ–º –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –±–µ–∑ AI
        faq_item, score = quick_result
        ai_response = faq_item.answer
        try:
            print(f"Quick FAQ match found (score: {score:.2f}), skipping AI")
        except UnicodeEncodeError:
            print("Quick FAQ match found, skipping AI")
    
    # –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ollama AI —Å –ø—Ä–æ–¥–∞—é—â–∏–º –ø—Ä–æ–º–ø—Ç–æ–º (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
    loading = None
    status_msg = None  # –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è streaming —Ä–µ–∂–∏–º–∞
    used_streaming = False  # –§–ª–∞–≥ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è streaming
    
    if not ai_response:
        try:
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
            is_ollama_available = await ollama_client.check_health()

            if is_ollama_available:
                # –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–¥–∞—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è chat API
                chat_messages = create_sales_chat_messages(
                    knowledge_base=knowledge_base,
                    conversation_history=conversation_history,
                    user_question=user_question,
                    lead_score=lead_score,
                    funnel_stage=funnel_stage,
                )
                
                try:
                    # –ü–æ–ø—ã—Ç–∫–∞ 1: Streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)
                    
                    # –ë–∞–∑–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏
                    BASE_PHRASES = [
                        "–î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º...",
                        "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–æ–ø—Ä–æ—Å...",
                        "–§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç...",
                    ]
                    
                    # –í—Ä–∞—â–∞—é—â–∏–µ—Å—è —ç–º–æ–¥–∑–∏ (—Ü–∏–∫–ª–∏—á–µ—Å–∫–∏ –º–µ–Ω—è—é—Ç—Å—è)
                    SPINNERS = ["üîÑ", "‚è≥", "‚åõ"]
                    
                    # –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–∞—Å–∏–≤–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ —Å —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏
                    def generate_progress_with_bar(phrase: str, spinner: str, progress: int) -> str:
                        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ —Å —Ü–≤–µ—Ç–Ω—ã–º–∏ —Ç–æ—á–∫–∞–º–∏.
                        
                        Args:
                            phrase: –¢–µ–∫—Å—Ç–æ–≤–∞—è —Ñ—Ä–∞–∑–∞
                            spinner: –ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–æ–¥–∑–∏
                            progress: –ü—Ä–æ–≥—Ä–µ—Å—Å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0-100)
                            
                        Returns:
                            str: –ü—Ä–æ–≥—Ä–µ—Å—Å —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º –±–∞—Ä–æ–º –≤ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏
                        """
                        width = 10
                        filled = int((progress / 100) * width)
                        empty = width - filled
                        # –§–∏–æ–ª–µ—Ç–æ–≤—ã–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –∏ –±–µ–ª—ã–µ –ø—É—Å—Ç—ã–µ
                        bar = "üü£" * filled + "‚ö™" * empty
                        return f"{spinner} {phrase}\n{bar} {progress}%"
                    
                    # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    status_msg = await message.answer(
                        generate_progress_with_bar(BASE_PHRASES[0], SPINNERS[0], 0)
                    )
                    start_time = datetime.now()
                    last_text_change = datetime.now()  # –î–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è —Å–º–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞
                    
                    # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ throttling
                    full_response: list[str] = []
                    last_update = datetime.now()
                    current_phrase_index = 0
                    MIN_UPDATE_INTERVAL = 1.0  # Telegram API limit: 1 req/sec
                    SPINNER_INTERVAL = 0.4  # –°–º–∞–π–ª–∏–∫ –∫—Ä—É—Ç–∏—Ç—Å—è –±—ã—Å—Ç—Ä–æ
                    TEXT_CHANGE_INTERVAL = 3.0  # –¢–µ–∫—Å—Ç –º–µ–Ω—è–µ—Ç—Å—è —Ä–µ–¥–∫–æ (–∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –≥–ª–∞–∑—É)
                    animation_stopped = False
                    
                    # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                    token_count = 0
                    estimated_max_tokens = 300  # –ò–∑ AI_MAX_TOKENS –≤ config
                    
                    # –§–æ–Ω–æ–≤–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ —Å –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
                    async def animate_thinking_indicator() -> None:
                        """–ê–Ω–∏–º–∏—Ä–æ–≤–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º."""
                        nonlocal token_count
                        spinner_index = 0
                        phrase_index = 0
                        last_text_change_time = datetime.now()
                        
                        try:
                            while not animation_stopped:
                                await asyncio.sleep(SPINNER_INTERVAL)  # –ë—ã—Å—Ç—Ä–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ —Å–º–∞–π–ª–∏–∫–∞
                                if not full_response and not animation_stopped:
                                    # –í—Ä–∞—â–∞—Ç—å —Å–º–∞–π–ª–∏–∫ –ö–ê–ñ–î–´–ô —Ü–∏–∫–ª (–±—ã—Å—Ç—Ä–æ)
                                    spinner_index = (spinner_index + 1) % len(SPINNERS)
                                    
                                    # –ú–µ–Ω—è—Ç—å —Ç–µ–∫—Å—Ç –†–ï–î–ö–û (–∫–∞–∂–¥—ã–µ TEXT_CHANGE_INTERVAL —Å–µ–∫—É–Ω–¥)
                                    elapsed_since_text = (datetime.now() - last_text_change_time).total_seconds()
                                    if elapsed_since_text >= TEXT_CHANGE_INTERVAL:
                                        phrase_index = (phrase_index + 1) % len(BASE_PHRASES)
                                        last_text_change_time = datetime.now()
                                    
                                    # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
                                    if token_count == 0:
                                        # –ò–º–∏—Ç–∞—Ü–∏—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
                                        elapsed = (datetime.now() - start_time).total_seconds()
                                        fake_progress = min(95, int(elapsed * 5))  # ~5% –≤ —Å–µ–∫—É–Ω–¥—É
                                        progress_text = generate_progress_with_bar(
                                            BASE_PHRASES[phrase_index],
                                            SPINNERS[spinner_index],
                                            fake_progress
                                        )
                                    else:
                                        # –†–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
                                        real_progress = min(99, int((token_count / estimated_max_tokens) * 100))
                                        progress_text = generate_progress_with_bar(
                                            "–ì–µ–Ω–µ—Ä–∏—Ä—É—é...",
                                            SPINNERS[spinner_index],
                                            real_progress
                                        )
                                    
                                    try:
                                        await status_msg.edit_text(progress_text, parse_mode=None)
                                    except Exception:
                                        pass
                        except asyncio.CancelledError:
                            pass
                    
                    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
                    animation_task = asyncio.create_task(animate_thinking_indicator())
                    
                    async def on_token(token: str) -> None:
                        """Callback –¥–ª—è —Å–±–æ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤ –±–µ–∑ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è."""
                        nonlocal animation_stopped, token_count
                        full_response.append(token)
                        token_count += 1
                        
                        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é
                        if token_count == 1 and not animation_stopped:
                            animation_stopped = True
                    
                    # –ó–∞–ø—É—Å—Ç–∏—Ç—å streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                    streaming_success = False
                    try:
                        ai_response = await ollama_client.chat_stream(
                            chat_messages,
                            on_token=on_token
                        )
                        
                        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –µ—Å–ª–∏ streaming —É—Å–ø–µ—à–µ–Ω, –æ—Ç–º–µ—á–∞–µ–º —ç—Ç–æ –°–†–ê–ó–£
                        if ai_response and len(ai_response.strip()) > 0:
                            streaming_success = True
                        
                    except Exception as streaming_error:
                        # –í–ê–ñ–ù–û: –ï—Å–ª–∏ streaming —É—Å–ø–µ—à–µ–Ω - –ù–ï –∑–∞–ø—É—Å–∫–∞—Ç—å fallback
                        if streaming_success:
                            # Streaming –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ, –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é
                            animation_stopped = True
                            animation_task.cancel()
                            try:
                                await animation_task
                            except asyncio.CancelledError:
                                pass
                        else:
                            # Streaming –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è - –∑–∞–ø—É—Å—Ç–∏—Ç—å fallback —Ä–µ–∂–∏–º
                            # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
                            animation_stopped = True
                            animation_task.cancel()
                            try:
                                await animation_task
                            except asyncio.CancelledError:
                                pass
                            
                            # –ü–æ–ø—ã—Ç–∫–∞ 2: Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –±–µ–∑ streaming
                            try:
                                print(f"Streaming failed: {streaming_error}, falling back to non-streaming mode")
                            except UnicodeEncodeError:
                                print("Streaming failed, falling back to non-streaming mode")
                            
                            # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è fallback —Ä–µ–∂–∏–º–∞
                            try:
                                await status_msg.edit_text("–î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º... üß†")
                            except Exception:
                                pass
                            
                            loading = await LoadingIndicator.start(message)
                            try:
                                ai_response = await ollama_client.chat(chat_messages)
                                # POST-PROCESSING: –û—á–∏—Å—Ç–∫–∞ –¥–ª—è fallback —Ä–µ–∂–∏–º–∞
                                if ai_response:
                                    ai_response = clean_text(ai_response)
                            finally:
                                await loading.stop()
                                # –£–¥–∞–ª–∏—Ç—å status_msg —Ç.–∫. LoadingIndicator —É–∂–µ —É–¥–∞–ª–∏–ª —Å–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                                try:
                                    await status_msg.delete()
                                except Exception:
                                    pass
                    
                    # –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê: –ï—Å–ª–∏ streaming —É—Å–ø–µ—à–µ–Ω, –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –í–ù–ï try –±–ª–æ–∫–∞
                    if streaming_success and ai_response:
                        # –û—á–∏—Å—Ç–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤ –∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
                        ai_response = clean_text(ai_response)
                        
                        # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é
                        animation_stopped = True
                        animation_task.cancel()
                        try:
                            await animation_task
                        except asyncio.CancelledError:
                            pass
                        
                        # –û—Ç–º–µ—Ç–∏—Ç—å —É—Å–ø–µ—à–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ streaming
                        used_streaming = True
                    
                except asyncio.TimeoutError:
                    # Timeout - –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ fallback –ø–æ–∏—Å–∫
                    print("Ollama timeout, switching to fallback")
                    try:
                        await status_msg.edit_text("–û—Ç–≤–µ—Ç –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏... üîç")
                    except Exception:
                        pass

        except Exception as e:
            try:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Ollama: {e}")
            except UnicodeEncodeError:
                print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Ollama")
            if loading:
                await loading.stop()
                loading = None
            # –£–¥–∞–ª–∏—Ç—å status_msg –µ—Å–ª–∏ –±—ã–ª —Å–æ–∑–¥–∞–Ω
            if status_msg:
                try:
                    await status_msg.delete()
                except Exception:
                    pass
                status_msg = None

    # –ü–æ–ø—ã—Ç–∫–∞ 3: Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ FAQ
    if not ai_response:
        try:
            print("Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç. –ò—Å–ø–æ–ª—å–∑—É—é fallback –ø–æ–∏—Å–∫.")
        except UnicodeEncodeError:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∫–æ–¥–∏—Ä–æ–≤–∫–∏

        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ FAQ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        found_faq = search_faq(
            query=user_question,
            knowledge_base=knowledge_base,
            top_k=1,
            min_score=0.2,  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ –¥–ª—è fallback —Ä–µ–∂–∏–º–∞
        )

        if found_faq:
            ai_response = format_faq_results(found_faq)
        else:
            # –ü–æ–ø—ã—Ç–∫–∞ 3: –£–º–Ω—ã–π fallback –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
            from src.utils.smart_fallback import (
                detect_general_intent,
                generate_fallback_response,
            )

            general_intent = detect_general_intent(user_question)

            if general_intent:
                ai_response = generate_fallback_response(
                    intent=general_intent,
                    knowledge_base=knowledge_base,
                    conversation_history=conversation_history,
                )

            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ - –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã
            if not ai_response:
                ai_response = knowledge_base.phrases.not_found.format(
                    phone=knowledge_base.company.phone,
                    email=knowledge_base.company.email,
                    telegram=knowledge_base.company.telegram,
                )

    # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ - –ø–æ–∫–∞–∑–∞—Ç—å –æ—à–∏–±–∫—É
    if not ai_response:
        ai_response = knowledge_base.phrases.error

    # –î–æ–±–∞–≤–∏—Ç—å hints –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    formatted_response = ai_response
    if should_show_hints(ai_response, intent):
        formatted_response += "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        formatted_response += "\nüí° –•–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ? –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /menu"

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –ë–î
    await context.save_message(
        user_id=user_id,
        role="assistant",
        content=ai_response,
    )

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–Ω–æ–ø–∫–∏
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –Ω–∞–º–µ—Ä–µ–Ω–∏–π, –Ω–µ –¥–ª—è general
    show_buttons = intent in ["pricing", "services", "contacts", "order"]
    
    # –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ quick replies –∫–Ω–æ–ø–∫–∏ (–∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –∏—Ö)
    reply_markup = contextual_quick_replies(intent, show_buttons=show_buttons)

    # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    if used_streaming and status_msg:
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ streaming - –æ–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        try:
            await status_msg.edit_text(
                text=formatted_response,
                reply_markup=reply_markup,
                parse_mode=None,
            )
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            try:
                await status_msg.delete()
            except Exception:
                pass
            await message.answer(
                text=formatted_response,
                reply_markup=reply_markup,
                parse_mode=None,
            )
    else:
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        # –£–¥–∞–ª–∏—Ç—å status_msg –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å (fallback —Ä–µ–∂–∏–º)
        if status_msg:
            try:
                await status_msg.delete()
            except Exception:
                pass
        
        await message.answer(
            text=formatted_response,
            reply_markup=reply_markup,
            parse_mode=None,  # –û—Ç–∫–ª—é—á–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ Markdown/HTML
        )

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑–∞—Ç—å onboarding –ø–æ–¥—Å–∫–∞–∑–∫—É
    # NOTE: –û–Ω–±–æ—Ä–¥–∏–Ω–≥ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ UX
    # stats = await context.get_user_stats(user_id)
    # message_count = stats["total_messages"] // 2  # –î–µ–ª–∏–º –Ω–∞ 2 —Ç.–∫. —Å–æ—Ö—Ä–∞–Ω—è–µ–º user+assistant

    # last_tip = _last_tips_shown.get(user_id)
    # if should_show_onboarding_tip(message_count, last_tip):
    #     tip = get_onboarding_tip(message_count)
    #     if tip:
    #         # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫—É —á–µ—Ä–µ–∑ –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É
    #         await asyncio.sleep(1)
    #         await message.answer(tip)
    #         _last_tips_shown[user_id] = message_count
